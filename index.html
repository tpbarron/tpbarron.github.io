<!DOCTYPE HTML>
<!--
	Solid State by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Trevor Barron - CS Graduate Student at ASU</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body>

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<h1><a href="index.html">Trevor Barron</a></h1>
						<nav>
							<a href="#news">News</a>
							<a href="#profile">Profile</a>
							<a href="#pubs">Publications</a>
							<a href="#projects">Projects</a>
							<a href="#footer">Contact</a>
							<a href="https://tpbarron.github.io/papers/TrevorBarronCV.pdf">CV</a>
							<!-- <a href="#menu">Menu</a> -->
						</nav>
					</header>

				<!-- Menu -->
					<!-- <nav id="menu">
						<div class="inner">
							<h2>Menu</h2>
							<ul class="links">
								<li><a href="index.html">Home</a></li>
								<li><a href="generic.html">Generic</a></li>
								<li><a href="elements.html">Elements</a></li>
							</ul>
							<a href="#" class="close">Close</a>
						</div>
					</nav> -->

				<!-- Banner -->
					<section id="banner">
						<div class="inner">
							<!-- <div class="logo"><span class="icon fa-diamond"></span></div> -->
							<h2>Trevor Barron</h2>
							<p>I am a masters student in the <a href="https://interactive-robotics.engineering.asu.edu/">Interactive Robotics Lab</a> at ASU focusing on reinforcement learning techniques for robot control.</p>
						</div>
					</section>

				<!-- Wrapper -->
					<section id="wrapper">

						<!-- One -->
							<section id="news" class="wrapper spotlight style1">
								<div class="inner">
									<!-- <a href="#" class="image"><img src="images/pic01.jpg" alt="" /></a> -->
									<div class="content">
										<h2 class="major">Recent News</h2>
										<!-- <p>Test</p> -->
										<ul class="alt" style="text-align: left;">
											<li><time datetime="2018-01"><b>January, 2018</b></time>: I am an RA funded by Intel tasked with creating educational material in machine learning and reinforcement learning.</li>
											<li><time datetime="2017-12"><b>December, 2017</b></time>: I am presenting my work on <i>Information Maximizing Exploration with a Latent Dynamics Model</i> at the NIPS 2017 Deep RL Symposium.</li>
											<li><time datetime="2017-09"><b>September, 2017</b></time>: I am a research assistant funded by Honda Research Institute studying the use of memory-augmented policies for long-term dependencies in reinforcement learning.</li>
											<li><time datetime="2017-08"><b>August, 2017</b></time>: I am a teaching assistant for the fall '17 iteration of CSE 571 Artificial Intelligence at ASU.</li>
											<li><time datetime="2017-08"><b>August, 2017</b></time>: I reviewed for Humanoids 2017.</li>
											<li><time datetime="2017-06"><b>June, 2017</b></time>: I am presenting my work on <i>Mutual Learning and Adaptation for Robot to Human Handover Tasks</i> at the 2017 Interdisciplinary Conference on Reinforcement Learning and Decision Making.</li>
											<li><time datetime="2017-05"><b>May, 2017</b></time>: I will be spending the summer interning at Honda Research in Mountain View, CA.</li>
										</ul>
									</div>
								</div>
							</section>

						<!-- Two -->
							<section id="profile" class="wrapper alt spotlight style2">
								<div class="inner">
									<!-- <a href="#" class="image"><img src="images/pic02.jpg" alt="" /></a> -->
									<div class="content">
										<h2 class="major">Profile - <a href="https://tpbarron.github.io/papers/TrevorBarronCV.pdf">My CV</a></h2>

										<h3 class="major">Industry Experience</h3>
										<ul class="alt">
											<li>5/2017&ndash;8/2017: <b>Summer intern at Honda Research Institute</b>. Mountain View, CA. Focused on RL applications to autonomous driving.</li>
											<li>6/2014&ndash;1/2015: <b>Software Engineer Associate at Lockheed Martin</b>. Colorado Springs, CO. Software engineer on the DIAMONDShield project.</li>
											<li>5/2012&ndash;8/2012: <b>Google Summer of Code Intern with Benetech</b>. Implemented text-to-speech for mathematical expressions.</li>
										</ul>

										<h3 class="major">Academic Experience</h3>
										<ul class="alt">
											<li>8/2017&ndash;Present: <b>Research Assistant and Teaching Assistant under Dr. Ben Amor; Interactive Robotics Lab, ASU</b>. Tempe, AZ. Working on project to improve RL algorithms with memory-augmented policies for partially observed domains with long temporal dependencies. I was also a TA for the graduate level AI course in Fall 2017. </li>
											<li>8/2016&ndash;5/2017: <b>Research Assistant under Dr. Ben Amor; Interactive Robotics Lab, ASU</b>. Tempe, AZ. Worked on a Toyota-funded project to optimize human-robot handovers with applications to both manufacturing and assisting those with physical impairments.</li>
											<li>5/2015&ndash;5/2016: <b>Computer Science Research Assistant and Paraprofessional, Colorado College</b>. Colorado Springs, CO. Tutor for computer science courses and research assistant to my undergraduate adviser.</li>
										</ul>

										<h3 class="major">Education</h3>
										<ul class="alt">
											<li>2016-present: <b>M.S. in Computer Science</b>. Arizona State University, Tempe, AZ.</li>
											<li>2011&ndash;2014: <b>B.A. in Computer Science</b>. Colorado College, Colorado Springs, CO. 3.89 GPA; 3.975 Major GPA. Distinction in Computer Science.</li>
										</ul>

										<h3 class="major">Awards</h3>
										<ul class="alt">
											<li>April 2013: <b>Won the Colorado College Big Idea Entrepreneurship Competition</b>. Mobile EEG brain monitoring application for epilepsy patients. Earned product development grant of $38,000. Assisted my partner's further development of the product.</li>

											<li>August 2012: <b>London Olympian in the 20km race walk</b>. Finished 26th with the fastest time ever by an American in the event; U.S. national champion in the 20km race walk, 2011 and 2012; youngest U.S. competitor at the 2011 World Track and Field Championships in Daegu, Korea, finishing 23rd of 46 entrants.</li>

											<li>Spring 2012: <b>Euclid Scholarship Recipient</b>. Awarded by the Colorado College Math and Computer Science department in recognition of exceptional promise in math and computer science.</li>

											<li>Fall 2012&ndash;Spring 2014: <b>Colorado College President's Council</b>. Served as an ambassador for Colorado College both internally and externally.</li>

											<li>Spring 2010: <b>National Engineering Design Challenge finalist</b>. Member of Stanford Online High School team that qualified for national finals in Washington, D.C. Developed a device that translated the lights on the phone indicating which line is in use or ringing to a tactile format that users with visual impairment could understand.</li>

											<li>Summer 2008: <b>University of Pittsburgh Gene Team Member</b>. Selected through competitive application process to participate in National Science Foundation-funded biomedical summer research program.</li>
										</ul>

									</div>
								</div>
							</section>

						<!-- Three -->
							<section id="pubs" class="wrapper spotlight style3">
								<div class="inner">
									<!-- <a href="#" class="image"><img src="images/pic03.jpg" alt="" /></a> -->
									<div class="content">
										<h2 class="major">Publications</h2>
										<textarea id="bibtex_input" style="display:none;">
											@article{barron2017infoexpl,
											  title={Information Maximizing Exploration with a Latent Dynamics Model},
											  author={Trevor Barron, Heni Ben Amor and Oliver Obst},
											  journal={Deep Reinforcement Learning Symposium, NIPS},
											  year="2017",
											  url="https://tpbarron.github.io/media/information-maximizing-exploration.pdf"
											}

											@article{barron2017sampleefficient,
											  title={Sample-Efficient Reinforcement Learning for Robot to Human Handover Tasks},
											  author={Trevor Barron and Heni Ben Amor},
											  journal={The Multi-disciplinary Conference on Reinforcement Learning and Decision Making},
											  year="2017"
											}

											@article{barron2016deep,
											  title={Deep reinforcement learning in a 3-d blockworld environment},
											  author={Trevor Barron, Matthew Whitehead and Alan Yeung},
											  journal={Deep Reinforcement Learning: Frontiers and Challenges, IJCAI},
											  year="2016"
											}

											@article{Barron2016ESANN,
											  author="Trevor Barron and Matthew Whitehead",
											  title="Visualizing Stacked Autoencoder Language Learning",
											  JOURNAL="European Symposium on Artificial Neural Networks",
											  YEAR="{2016}"
											}

											@misc{Barron2013Midstates,
											  author="Trevor Barron and Matthew Whitehead",
											  title="Latent Semantic Indexing and Word Vector Representations",
											  YEAR="2013",
											  journal={Undergraduate Research Symposium in the Physical Sciences, Math, and Computer Science at the University of Chicago},
											  NOTE="Poster presented at the 2013 Undergraduate Research Symposium in the Physical Sciences, Math, and Computer Science at the University of Chicago, October 25&ndash;26, University of Chicago, Chicago, Illinois"
											}
										</textarea>

										<div id="bibtex_display" class="alt" style="text-align: left;"></div>
										<div class="bibtex_template">
											<span class="if title">
											  <a class="bibtexVar" href="https://tpbarron.github.io/papers/+BIBTEXKEY+.pdf" extra="BIBTEXKEY">
											    <span class="title"></span>
											  </a>
											</span>
											<div class="if author">
											  <span class="author"></span>
											</div>
											<div>
											  <span class="if journal"><span class="journal"></span>.</span>
											  <span class="if month"><span class="month"></span>,</span>
											  <span class="if year"><span class="year"></span></span>.
											</div>
											<br />
										</div>
									</div>
								</div>
							</section>

						<!-- Four -->
							<section id="projects" class="wrapper alt style1">
								<div class="inner">
									<h2 class="major">Projects</h2>
									<p>A summary of some recent projects.</p>
									<section class="features">
										<article>
											<!-- <a href="#" class="image"><img src="images/pic04.jpg" alt="" /></a> -->
											<div class="image"><img src="images/walker2d.png" alt="" /></div>
											<h3 class="major">Information Maximizing Exploration with a Latent Dynamics Model</h3>
											<p>
												This work extended a previous exploration method, Variational Information Maximizing Exploration, that is based on the idea of optimism in the face of uncertainty. Essentially, we incentivize exploring parts of the environment about which little is known.
											</p>
											<p>
												In VIME, a separate Bayesian dynamics model is learned and intrinsic reward bonuses are derived from the amount of information gained by visiting a state. Our key observation is based on a <a href="https://users.cs.duke.edu/~parr/icml08.pdf">relationship</a> between linear one-step forward models and linear value estimates. We propose fitting the dynamics model in the features found by the final hidden layer of the neural network value estimator. This has two significant advantages: (1) the dimensionality of the inputs are untied from the dimensionality of the Bayesian model and (2) the theory suggests that since the value estimate is linear in these features, the model can be as well. This simplifies the Bayesian modeling. We find this to be the case and observe that information maximizing exploration in the latent space performs comparable or better than VIME.
											</p>
											<!-- <a href="#" class="special">Learn more</a> -->
										</article>
										<article>
											<!-- <a href="#" class="image"><img src="images/pic05.jpg" alt="" /></a> -->
											<div class="image"><img src="images/robothandover.png" alt="" /></div>
											<h3 class="major">Mutual Learning and Adaptation for Robot to Human Handover Tasks</h3>
											<p>
												We focus on sample-efficient reinforcement learning in the context of a human with a disability. An initial policy is defined by imitation, which is then adapted to someone which a particular impairment according to some objective (distance to the human's hand, for example). We are able to learn efficient trajectories for object handovers from robot to human in as few as 50 trials.
											</p>
											<p>
												This work was presented at the 2017 Interdisciplinary Conference on Reinforcement Learning and Decision Making.
											</p>
											<!-- <a href="#" class="special">Learn more</a> -->
										</article>
										<article>
											<!-- <a href="#" class="image"><img src="images/pic06.jpg" alt="" /></a> -->
											<div class="image"><img src="images/3d_infer.png" alt="" /></div>
											<h3 class="major">Reinforcement learning for tasks in a 3D environment using only visual input</h3>
											<p>
												Deep reinforcement learning is an effective method for  training  autonomous  agents  to  a  high  level of  performance  on  visual  tasks. This work  explores  how  reinforcement  learning  agents  using
												deep Q-networks perform when visually processing
												3-D virtual environments and how deeper network
												architectures  can  improve  performance  given  the
												added difficulties of more complex environments.

												We explored ways to handle 3D environments such as providing a point-cloud representation of the agent's environment or a depth map as input to the network. We found, however, that depth can accurately be inferred from 2D inputs in structured environments.

												We provide results for tests on a variety of tasks in
												a  virtual  3-D  world  and  show  that  deeper  convolutional neural networks lead to increased performnce.
											</p>
											<!-- <a href="#" class="special">Learn more</a> -->
										</article>
										<article>
											<!-- <a href="#" class="image"><img src="images/pic07.jpg" alt="" /></a> -->
											<div class="image"><img src="images/wordcloud_644x400.jpeg" alt="" /></div>
											<h3 class="major">Visualizing Natural Language Features in Stacked Autoencoders</h3>
											<p>
												Visualizing the features of unsupervised deep networks is an important part of understanding what a network has learned. In this paper, we present a method for visualizing a deep autoencoder's hidden layers when trained on natural language data with t-SNE plots and wordclouds. Our method is complementary to training error analysis and it can help determine an appropriate stopping point in the training process. It can also provide researchers insight into the semantic language features the network has extracted from the dataset. Finally, it can show a big picture view of what a network has learned and how the various features the network has extracted relate to one another in semantic hierarchies. We hope that these benefits will aid human understanding of deep networks and can help guide future experiments.
												<!-- We trained a stacked autoencoder on large text dataset derived from Wikipedia and visualized learned features with t-SNE and wordcloud techniques to understand how deep networks learn on natural language data. -->
											</p>
											<!-- <a href="#" class="special">Learn more</a> -->
										</article>
									</section>
									<!-- <ul class="actions">
										<li><a href="#" class="button">Browse All Projects</a></li>
									</ul> -->
								</div>
							</section>

					</section>

				<!-- Footer -->
					<section id="footer">
						<div class="inner">
							<h2 class="major">Get in touch</h2>
							<p>Send me a message, questions, or view my work online.</p>

							<ul class="contact">
								<li class="fa-github"><a href="https://github.com/tpbarron">@tpbarron</a></li>
								<li class="fa-envelope"><a href="#">lastname.firstname@gmail.com</a></li>
							</ul>
							<!-- <ul class="copyright">
								<li>&copy; Untitled Inc. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

			<!-- bibtex parser -->
			<script type="text/javascript" src="https://cdn.rawgit.com/pcooksey/bibtex-js/b81606e85986fa8ad0eb66954493bc1c0b3d7ab1/src/bibtex_js.js"></script>

	</body>
</html>
